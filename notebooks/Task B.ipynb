{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B: Meta-Learning Perfomance Prediction\n",
    "\n",
    "In this task, you will use information on training parameters and metadata on multiple OpenML dataset to train a performance predictor that performs well even for unseen datasets. You are provided with config parameters and metafeatures for six datasets. The datasets are split into training datasets and test datasets and you should only train on the training datasets.\n",
    "\n",
    "For questions, you can contact zimmerl@informatik.uni-freiburg.de\n",
    "\n",
    "__Note: Please use the dataloading and splits you are provided with in this notebook.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications:\n",
    "\n",
    "* Data: six_datasets_lw.json\n",
    "* Number of datasets: 6\n",
    "* Training datasets: higgs, vehicle, adult, volkert\n",
    "* Test datasets: Fashion-MNIST, jasmine\n",
    "* Number of configurations: 2000\n",
    "* Available data: architecture parameters and hyperparameters, metafeatures \n",
    "* Target: final validation accuracy\n",
    "* Evaluation metric: MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing\n",
    "\n",
    "Note: There are 51 steps logged, 50 epochs plus the 0th epoch, prior to any weight updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd ..\n",
    "#external\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#local\n",
    "sys.path.append(\"../\")\n",
    "from func.networks.FNN_meta_WO_HPO_5Layer import FNN_meta_WO_HPO_5Layer\n",
    "from func.train_eval import train_model, eval_model\n",
    "from func.load_data import prepare_dataloaders, load_data_from_file\n",
    "from func.number_neurons import number_neurons, Capturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with Capturing() as output:\n",
    "        number_neurons(0, 100, 5, 5)\n",
    "print(output)"
   ]
  },
  {
   "source": [
    "## Cuda config"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "source": [
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_metafeatures_train, y_train, X_val, X_metafeatures_val, y_val, X_test, X_metafeatures_test, y_test    =   load_data_from_file(\"cached/six_datasets_lw.json\", \"cached/metafeatures_6.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print()\n",
    "print(\"Y_Train:\",y_train.shape)\n",
    "print(\"Y_val:\",y_val.shape)\n",
    "print(\"Y_Test:\",y_test.shape)\n",
    "print()\n",
    "print(\"X_metafeatures_train:\",X_metafeatures_train.shape)\n",
    "print(\"X_metafeatures_val:\" ,X_metafeatures_val.shape)\n",
    "print(\"X_metafeatures_test:\" , X_metafeatures_test.shape)"
   ]
  },
  {
   "source": [
    "## "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Prepare data\n",
    "## Preprocess data + Create dataloaders for the preprocessed data tensors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_dataloader = prepare_dataloaders(X_hp=X_train, X_mf=X_metafeatures_train, y= y_train, scaling=\"minmax\",batch_size=batch_size)\n",
    "validation_dataloader = prepare_dataloaders(X_hp=X_val, X_mf=X_metafeatures_val, y= y_val, scaling=\"minmax\",batch_size=batch_size)\n",
    "test_dataloader = prepare_dataloaders(X_hp=X_test, X_mf=X_metafeatures_test, y= y_test, scaling=\"minmax\",batch_size=batch_size)"
   ]
  },
  {
   "source": [
    "## Check the data in the tensors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x,  y in train_dataloader:\n",
    "    print(\"X- minibatched: \", x)\n",
    "    print(\"y- minibatched: \", y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = FNN_meta_WO_HPO_5Layer(55, 1)\n",
    "print(\"Model:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 70\n",
    "optimizer  = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50)\n",
    "criterion = nn.MSELoss()\n",
    "train_model(train_dataloader, validation_dataloader, epochs, model, optimizer, scheduler, criterion)\n",
    "#eval_model(test_dataloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Custom neural network tuned with BOHB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.NN_HPO import PyTorchWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.curdir\n",
    "# minimum budget that BOHB uses\n",
    "min_budget = 1\n",
    "# largest budget BOHB will use\n",
    "max_budget = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker = PyTorchWorker(run_id='0', input_size=55, output_size=1, train_loader=train_dataloader, validation_loader=validation_dataloader, test_loader=test_dataloader)\n",
    "cs = worker.get_configspace()\n",
    "\n",
    "config = cs.sample_configuration().get_dictionary()\n",
    "print(config)\n",
    "\n",
    "res = worker.compute(config=config, budget=min_budget, working_directory=working_dir)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}