{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B: Meta-Learning Perfomance Prediction\n",
    "\n",
    "In this task, you will use information on training parameters and metadata on multiple OpenML dataset to train a performance predictor that performs well even for unseen datasets. You are provided with config parameters and metafeatures for six datasets. The datasets are split into training datasets and test datasets and you should only train on the training datasets.\n",
    "\n",
    "For questions, you can contact zimmerl@informatik.uni-freiburg.de\n",
    "\n",
    "__Note: Please use the dataloading and splits you are provided with in this notebook.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications:\n",
    "\n",
    "* Data: six_datasets_lw.json\n",
    "* Number of datasets: 6\n",
    "* Training datasets: higgs, vehicle, adult, volkert\n",
    "* Test datasets: Fashion-MNIST, jasmine\n",
    "* Number of configurations: 2000\n",
    "* Available data: architecture parameters and hyperparameters, metafeatures \n",
    "* Target: final validation accuracy\n",
    "* Evaluation metric: MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing\n",
    "\n",
    "Note: There are 51 steps logged, 50 epochs plus the 0th epoch, prior to any weight updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd ..\n",
    "#external\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#local\n",
    "from func.api import Benchmark\n",
    "from func.preprocess import delete_constant_features_X,reshape_op, scale_features, create_metafeatures_2d, concatenate_metafeatures_features\n",
    "from func.networks.FNN_WO_HPO import FNN_WO_HPO\n",
    "from func.networks.FNN_WO_HPO_BN import FNN_WO_HPO_BN\n",
    "from func.networks.FNN_meta_WO_HPO import FNN_meta_WO_HPO\n",
    "from func.train_eval import train_model, eval_model\n",
    "from func.parse_metafeatures import parse_metafeatures_dict, remove_nan_metafeatures, create_metafeatures_array\n",
    "from func.load_data import read_data, TrainValSplitter"
   ]
  },
  {
   "source": [
    "## Cuda config"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "source": [
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bench_dir = \"cached/six_datasets_lw.json\"\n",
    "bench = Benchmark(bench_dir, cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset split\n",
    "dataset_names_all = bench.get_dataset_names()\n",
    "print(dataset_names_all)\n",
    "\n",
    "train_datasets = ['adult', 'higgs', 'vehicle', 'volkert']\n",
    "test_datasets = ['Fashion-MNIST', 'jasmine']"
   ]
  },
  {
   "source": [
    "## Meta feature handling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cached/metafeatures_6.json\", \"r\") as f:\n",
    "    metafeatures = json.load(f)\n",
    "metafeatures_without_nan = remove_nan_metafeatures(metafeatures)         "
   ]
  },
  {
   "source": [
    "## Prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read the data and create ndarrays\n",
    "X, y, dataset_names_TV = read_data(bench, train_datasets)\n",
    "X_test, y_test, dataset_names_test = read_data(bench, test_datasets)\n",
    "X_metafeatures_TV = create_metafeatures_array(metafeatures_without_nan, train_datasets)\n",
    "X_metafeatures_test = create_metafeatures_array(metafeatures_without_nan, test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tv_splitter = TrainValSplitter(dataset_names=dataset_names_TV)\n",
    "X_train, X_val = tv_splitter.split(X)\n",
    "y_train, y_val = tv_splitter.split(y)\n",
    "dataset_names_train, dataset_names_val = tv_splitter.split(dataset_names_TV)\n",
    "X_metafeatures_train, X_metafeatures_val = tv_splitter.split(X_metafeatures_TV)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print()\n",
    "print(\"Y_Train:\",y_train.shape)\n",
    "print(\"Y_val:\",y_val.shape)\n",
    "print(\"Y_Test:\",y_test.shape)\n",
    "print()\n",
    "print(\"X_metafeatures_train:\",X_metafeatures_train.shape)\n",
    "print(\"X_metafeatures_val:\" ,X_metafeatures_val.shape)\n",
    "print(\"X_metafeatures_test:\" , X_metafeatures_test.shape)"
   ]
  },
  {
   "source": [
    "## Preprocess data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#delete constant features and reshape the arrays\n",
    "X_train_transformed = delete_constant_features_X(X_train)\n",
    "X_val_transformed = delete_constant_features_X(X_val)\n",
    "X_test_transformed = delete_constant_features_X(X_test)\n",
    "\n",
    "print(\"X_train_transformed:\", X_train_transformed.shape)\n",
    "print(\"X_val_transformed:\", X_val_transformed.shape)\n",
    "print(\"X_test_transformed:\", X_test_transformed.shape)\n",
    "print()\n",
    "\n",
    "y_train_transformed = reshape_op(y_train)\n",
    "y_val_transformed = reshape_op(y_val)\n",
    "y_test_transformed = reshape_op(y_test)\n",
    "\n",
    "print(\"y_train_transformed: \",y_train_transformed.shape )\n",
    "print(\"y_val_transformed: \",y_val_transformed.shape)\n",
    "print(\"y_test_transformed: \", y_test_transformed.shape)\n",
    "print()\n",
    "\n",
    "X_metafeatures_train_transformed = create_metafeatures_2d(X_metafeatures_train)\n",
    "X_metafeatures_val_transformed = create_metafeatures_2d(X_metafeatures_val)\n",
    "X_metafeatures_test_transformed = create_metafeatures_2d(X_metafeatures_test)\n",
    "\n",
    "print(\"X_metafeatures_train_transformed:\",X_metafeatures_train_transformed.shape)\n",
    "print(\"X_metafeatures_val_transformed:\" ,X_metafeatures_val_transformed.shape)\n",
    "print(\"X_metafeatures_test_transformed:\" , X_metafeatures_test_transformed.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "X_train_scaled = scale_features(X_train_transformed, method=\"minmax\")\n",
    "X_val_scaled = scale_features(X_val_transformed, method=\"minmax\")\n",
    "X_test_scaled = scale_features(X_test_transformed, method=\"minmax\")\n",
    "\n",
    "print(\"X_train_scaled:\", X_train_scaled.shape)\n",
    "print(\"X_val_scaled:\", X_val_scaled.shape)\n",
    "print(\"X_test_scaled:\", X_test_scaled.shape)\n",
    "print()\n",
    "\n",
    "y_train_scaled = scale_features(y_train_transformed, method=\"minmax\")\n",
    "y_val_scaled = scale_features(y_val_transformed, method=\"minmax\")\n",
    "y_test_scaled = scale_features(y_test_transformed, method=\"minmax\")\n",
    "\n",
    "print(\"y_train_scaled:\", y_train_scaled.shape)\n",
    "print(\"y_val_scaled:\", y_val_scaled.shape)\n",
    "print(\"y_test_scaled:\", y_test_scaled.shape)\n",
    "print()\n",
    "\n",
    "X_metafeatures_train_scaled = scale_features(X_metafeatures_train_transformed, method=\"minmax\")\n",
    "X_metafeatures_val_scaled = scale_features(X_metafeatures_val_transformed, method=\"minmax\")\n",
    "X_metafeatures_test_scaled = scale_features(X_metafeatures_test_transformed, method=\"minmax\")\n",
    "\n",
    "print(\"X_metafeatures_train_scaled:\",X_metafeatures_train_scaled.shape)\n",
    "print(\"X_metafeatures_val_scaled:\" ,X_metafeatures_val_scaled.shape)\n",
    "print(\"X_metafeatures_test_scaled:\" , X_metafeatures_test_scaled.shape)\n",
    "print()"
   ]
  },
  {
   "source": [
    "## Hyperparameters + Metafeatures  -> New feature matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_features_train = concatenate_metafeatures_features(X_train_scaled, X_metafeatures_train_scaled)\n",
    "X_features_val = concatenate_metafeatures_features(X_val_scaled, X_metafeatures_val_scaled)\n",
    "X_features_test = concatenate_metafeatures_features(X_test_scaled, X_metafeatures_test_scaled)\n",
    "\n",
    "print(\"X_features_train:\",X_features_train.shape)\n",
    "print(\"X_features_val:\" ,X_features_val.shape)\n",
    "print(\"X_features_test:\" , X_features_test.shape)\n",
    "print()"
   ]
  },
  {
   "source": [
    "## Convert all numpy arrays to pytorch tensors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert ndarray to pytorch tensor\n",
    "X_train_tensor = torch.from_numpy(X_features_train.astype(np.float32))\n",
    "X_val_tensor = torch.from_numpy(X_features_val.astype(np.float32))\n",
    "X_test_tensor = torch.from_numpy(X_features_test.astype(np.float32))\n",
    "\n",
    "print(\"X_train_tensor: \",X_train_tensor.shape)\n",
    "print(\"X_val_tensor: \",X_val_tensor.shape)\n",
    "print(\"X_test_tensor: \",X_test_tensor.shape)\n",
    "print()\n",
    "\n",
    "y_train_tensor = torch.from_numpy(y_train_scaled.astype(np.float32))\n",
    "y_val_tensor = torch.from_numpy(y_val_scaled.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(y_test_scaled.astype(np.float32))\n",
    "\n",
    "print(\"y_train_tensor: \",y_train_tensor.shape )\n",
    "print(\"y_val_tensor: \",y_val_tensor.shape)\n",
    "print(\"y_test_tensor: \", y_test_tensor.shape)\n",
    "print()"
   ]
  },
  {
   "source": [
    "## Settings for baseline FNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "n_samples, n_features  = X_train_tensor.shape\n",
    "hidden_units = 7\n",
    "_ , output_size = y_train_tensor.shape\n",
    "epochs = 70\n",
    "\n",
    "print(\"# Training samples:\", n_samples)\n",
    "print(\"# Features per sample or inputs for 1st layer:\", n_features)\n",
    "print(\"output_size: \", output_size)"
   ]
  },
  {
   "source": [
    "## DataLoading"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor,y_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=2)\n",
    "\n",
    "validation_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=1, shuffle=True,num_workers=2)"
   ]
  },
  {
   "source": [
    "## Check the data in the tensors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x,  y in train_dataloader:\n",
    "    print(\"X- minibatched: \", x)\n",
    "    print(\"y- minibatched: \", y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = FNN_meta_WO_HPO(n_features, output_size)\n",
    "print(\"Model:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer  = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100)\n",
    "criterion = nn.MSELoss()\n",
    "train_model(train_dataloader, validation_dataloader, epochs, model, optimizer, scheduler, criterion)\n",
    "#eval_model(test_dataloader, model, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}