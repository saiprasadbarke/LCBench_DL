{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B: Meta-Learning Perfomance Prediction\n",
    "\n",
    "In this task, you will use information on training parameters and metadata on multiple OpenML dataset to train a performance predictor that performs well even for unseen datasets. You are provided with config parameters and metafeatures for six datasets. The datasets are split into training datasets and test datasets and you should only train on the training datasets.\n",
    "\n",
    "For questions, you can contact zimmerl@informatik.uni-freiburg.de\n",
    "\n",
    "__Note: Please use the dataloading and splits you are provided with in this notebook.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications:\n",
    "\n",
    "* Data: six_datasets_lw.json\n",
    "* Number of datasets: 6\n",
    "* Training datasets: higgs, vehicle, adult, volkert\n",
    "* Test datasets: Fashion-MNIST, jasmine\n",
    "* Number of configurations: 2000\n",
    "* Available data: architecture parameters and hyperparameters, metafeatures \n",
    "* Target: final validation accuracy\n",
    "* Evaluation metric: MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing\n",
    "\n",
    "Note: There are 51 steps logged, 50 epochs plus the 0th epoch, prior to any weight updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd ..\n",
    "#external\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#local\n",
    "sys.path.append(\"../\")\n",
    "from networks.MyMLP import MyMLP\n",
    "from func.train_eval import train_model, eval_model\n",
    "from func.load_data import prepare_dataloaders, load_data_from_file"
   ]
  },
  {
   "source": [
    "## Cuda config"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "source": [
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Path to hyperparameters data:  c:\\Users\\saipr\\Documents\\Deep Learning\\ws19\\LCBench_DL/cached/six_datasets_lw.json\nPath to metafeatures data:  c:\\Users\\saipr\\Documents\\Deep Learning\\ws19\\LCBench_DL/cached/metafeatures_6.json\n==&gt; Loading data...\n==&gt; No cached data found or cache set to False.\n==&gt; Reading json data...\n==&gt; Done.\nAvailable datasets:  [&#39;Fashion-MNIST&#39;, &#39;adult&#39;, &#39;higgs&#39;, &#39;jasmine&#39;, &#39;vehicle&#39;, &#39;volkert&#39;]\nTrain-Validation-Test split: 6000-2000-4000\n"
    }
   ],
   "source": [
    "X_train, X_metafeatures_train, y_train, X_val, X_metafeatures_val, y_val, X_test, X_metafeatures_test, y_test    =   load_data_from_file(\"cached/six_datasets_lw.json\", \"cached/metafeatures_6.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X_train: (6000,)\nX_val: (2000,)\nX_test: (4000,)\n\nY_Train: (6000,)\nY_val: (2000,)\nY_Test: (4000,)\n\nX_metafeatures_train: (6000,)\nX_metafeatures_val: (2000,)\nX_metafeatures_test: (4000,)\n"
    }
   ],
   "source": [
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print()\n",
    "print(\"Y_Train:\",y_train.shape)\n",
    "print(\"Y_val:\",y_val.shape)\n",
    "print(\"Y_Test:\",y_test.shape)\n",
    "print()\n",
    "print(\"X_metafeatures_train:\",X_metafeatures_train.shape)\n",
    "print(\"X_metafeatures_val:\" ,X_metafeatures_val.shape)\n",
    "print(\"X_metafeatures_test:\" , X_metafeatures_test.shape)"
   ]
  },
  {
   "source": [
    "## "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Prepare data\n",
    "## Preprocess data + Create dataloaders for the preprocessed data tensors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_dataloader = prepare_dataloaders(X_hp=X_train, X_mf=X_metafeatures_train, y= y_train, X_scaling=\"minmax\",y_scaling=\"minmax\",batch_size=batch_size, typeD = \"tensor\")\n",
    "validation_dataloader = prepare_dataloaders(X_hp=X_val, X_mf=X_metafeatures_val, y= y_val, X_scaling=\"minmax\",y_scaling=\"minmax\",batch_size=batch_size, typeD = \"tensor\")\n",
    "test_dataloader = prepare_dataloaders(X_hp=X_test, X_mf=X_metafeatures_test, y= y_test, X_scaling=\"minmax\", y_scaling=\"minmax\",batch_size=batch_size, typeD = \"tensor\")"
   ]
  },
  {
   "source": [
    "## Check the data in the tensors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X- minibatched:  tensor([[3.3333e-01, 3.3463e-01, 9.2101e-01, 2.2222e-02, 7.2249e-01, 7.9896e-01,\n         2.7851e-01, 0.0000e+00, 1.0000e+00, 1.2671e-01, 0.0000e+00, 2.4391e-01,\n         1.0000e+00, 2.9180e-06, 2.0513e-01, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n         0.0000e+00, 8.6747e-01, 1.0000e+00, 0.0000e+00, 3.7387e-01, 7.8291e-04,\n         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5248e-02, 0.0000e+00,\n         1.0000e+00, 1.0000e+00, 5.9117e-01, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n         1.0000e+00, 1.4323e-04, 1.0000e+00, 0.0000e+00, 8.1463e-01, 0.0000e+00,\n         1.0000e+00, 0.0000e+00, 3.5750e-01, 0.0000e+00, 5.5647e-01, 0.0000e+00,\n         0.0000e+00],\n        [0.0000e+00, 1.4440e-03, 8.5039e-01, 6.0606e-03, 8.1889e-01, 2.6042e-02,\n         1.0561e-01, 1.0000e+00, 0.0000e+00, 5.1190e-04, 1.0000e+00, 7.1571e-01,\n         7.3652e-02, 1.0000e+00, 1.0000e+00, 2.5875e-01, 1.0000e+00, 5.8947e-01,\n         1.0000e+00, 1.0000e+00, 9.4840e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n         0.0000e+00, 7.7516e-01, 9.9183e-01, 4.8192e-01, 2.4961e-01, 1.0000e+00,\n         0.0000e+00, 0.0000e+00, 4.9377e-01, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n         6.5463e-01, 8.7882e-01, 2.6878e-01, 1.0000e+00, 1.0000e+00, 7.2777e-01,\n         7.7297e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n         1.0000e+00],\n        [0.0000e+00, 7.0345e-01, 7.2489e-01, 7.6162e-01, 4.3194e-01, 7.9062e-01,\n         3.1064e-01, 7.2625e-01, 9.4027e-02, 0.0000e+00, 5.7098e-01, 1.0000e+00,\n         4.3060e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1691e-06, 6.4187e-02,\n         1.5032e-05, 0.0000e+00, 1.4812e-01, 3.7150e-05, 0.0000e+00, 0.0000e+00,\n         0.0000e+00, 1.0000e+00, 6.3486e-02, 1.0000e+00, 1.0000e+00, 5.0000e-01,\n         0.0000e+00, 8.4337e-02, 1.0000e+00, 2.7624e-04, 1.3921e-03, 1.2644e-01,\n         0.0000e+00, 2.5862e-01, 1.3761e-04, 3.5868e-04, 9.5129e-01, 4.8712e-02,\n         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9036e-02, 8.3922e-02, 1.1081e-02,\n         1.5709e-01, 4.7890e-03, 2.0879e-01, 1.9963e-05, 2.6833e-01, 2.8889e-05,\n         0.0000e+00],\n        [0.0000e+00, 1.0882e-02, 9.8549e-01, 1.0101e-01, 7.4986e-01, 6.2708e-01,\n         4.3817e-01, 1.0000e+00, 0.0000e+00, 5.1190e-04, 1.0000e+00, 7.1571e-01,\n         7.3652e-02, 1.0000e+00, 1.0000e+00, 2.5875e-01, 1.0000e+00, 5.8947e-01,\n         1.0000e+00, 1.0000e+00, 9.4840e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n         0.0000e+00, 7.7516e-01, 9.9183e-01, 4.8192e-01, 2.4961e-01, 1.0000e+00,\n         0.0000e+00, 0.0000e+00, 4.9377e-01, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n         6.5463e-01, 8.7882e-01, 2.6878e-01, 1.0000e+00, 1.0000e+00, 7.2777e-01,\n         7.7297e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n         1.0000e+00]])\ny- minibatched:  tensor([[0.5099],\n        [0.9329],\n        [0.7415],\n        [0.9270]])\n"
    }
   ],
   "source": [
    "for x,  y in train_dataloader:\n",
    "    print(\"X- minibatched: \", x)\n",
    "    print(\"y- minibatched: \", y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model:\nSequential(\n  (fc1): Linear(in_features=55, out_features=44, bias=True)\n  (dropout1): Dropout(p=0.5, inplace=False)\n  (relu1): ReLU()\n  (fc2): Linear(in_features=44, out_features=33, bias=True)\n  (dropout2): Dropout(p=0.5, inplace=False)\n  (relu2): ReLU()\n  (fc3): Linear(in_features=33, out_features=22, bias=True)\n  (dropout3): Dropout(p=0.5, inplace=False)\n  (relu3): ReLU()\n  (fc4): Linear(in_features=22, out_features=11, bias=True)\n  (dropout4): Dropout(p=0.5, inplace=False)\n  (relu4): ReLU()\n  (fc5): Linear(in_features=11, out_features=1, bias=True)\n)\n[1] Training loss: 0.1972\t Validation loss: 0.1819\n[2] Training loss: 0.1680\t Validation loss: 0.1570\n[3] Training loss: 0.1448\t Validation loss: 0.1336\n[4] Training loss: 0.1252\t Validation loss: 0.1136\n[5] Training loss: 0.1083\t Validation loss: 0.0944\n[6] Training loss: 0.0942\t Validation loss: 0.0774\n[7] Training loss: 0.0839\t Validation loss: 0.0640\n[8] Training loss: 0.0769\t Validation loss: 0.0555\n[9] Training loss: 0.0704\t Validation loss: 0.0486\n[10] Training loss: 0.0641\t Validation loss: 0.0446\n"
    }
   ],
   "source": [
    "MyMLP = MyMLP(5, 0.5, 55, 1)\n",
    "print(\"Model:\")\n",
    "print(MyMLP.model)\n",
    "model = MyMLP.model\n",
    "epochs = 10\n",
    "optimizer  = optim.Adam(model.parameters(), lr=1e-05)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, eta_min=1e-05)\n",
    "criterion = nn.MSELoss()\n",
    "state_dict, training_losses, validation_losses = train_model(train_dataloader, validation_dataloader, epochs, model, optimizer, scheduler, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Final test loss: 0.0760\n"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)\n",
    "test_losses = eval_model(test_dataloader, model, criterion)"
   ]
  },
  {
   "source": [
    "## Plotting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (9,) and (10,)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m&lt;ipython-input-9-aae9295544fb&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----&gt; 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;r&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m&#39;Training loss&#39;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;b&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m&#39;Validation loss&#39;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;g&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m&#39;Test loss&#39;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m&#39;Training, Validation and Test loss&#39;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\saipr\\Documents\\Deep Learning\\ws19\\LCBench_DL\\.venv\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2838\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2839\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-&gt; 2840\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   2841\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2842\u001b[0m         **({&quot;data&quot;: data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32mc:\\Users\\saipr\\Documents\\Deep Learning\\ws19\\LCBench_DL\\.venv\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         &quot;&quot;&quot;\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-&gt; 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\saipr\\Documents\\Deep Learning\\ws19\\LCBench_DL\\.venv\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\saipr\\Documents\\Deep Learning\\ws19\\LCBench_DL\\.venv\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 399\u001b[1;33m             raise ValueError(f&quot;x and y must have same first dimension, but &quot;\n\u001b[0m\u001b[0;32m    400\u001b[0m                              f&quot;have shapes {x.shape} and {y.shape}&quot;)\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m&gt;\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m&gt;\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (9,) and (10,)"
     ]
    }
   ],
   "source": [
    "epochs = range(1, epochs)\n",
    "plt.plot(epochs, training_losses, 'r', label='Training loss')\n",
    "plt.plot(epochs, validation_losses, 'b', label='Validation loss')\n",
    "plt.plot(epochs, test_losses, 'g', label='Test loss')\n",
    "plt.title('Training, Validation and Test loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}