{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Neural network tuned with BOHB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpbandster.core.nameserver as hpns\n",
    "import hpbandster.core.result as hpres\n",
    "from hpbandster.optimizers import BOHB\n",
    "import hpbandster.visualization as hpvis\n",
    "import logging\n",
    "import pickle\n",
    "logging.getLogger('hpbandster').setLevel(logging.DEBUG)\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from func.load_data import prepare_dataloaders, load_data_from_file"
   ]
  },
  {
   "source": [
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_metafeatures_train, y_train, X_val, X_metafeatures_val, y_val, X_test, X_metafeatures_test, y_test    =   load_data_from_file(\"cached/six_datasets_lw.json\", \"cached/metafeatures_6.json\")"
   ]
  },
  {
   "source": [
    "## Prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_dataloader = prepare_dataloaders(X_hp=X_train, X_mf=X_metafeatures_train, y= y_train, scaling=\"minmax\",batch_size=batch_size, typeD = \"tensor\")\n",
    "validation_dataloader = prepare_dataloaders(X_hp=X_val, X_mf=X_metafeatures_val, y= y_val, scaling=\"minmax\",batch_size=batch_size, typeD = \"tensor\")\n",
    "test_dataloader = prepare_dataloaders(X_hp=X_test, X_mf=X_metafeatures_test, y= y_test, scaling=\"minmax\",batch_size=batch_size, \n",
    "typeD = \"tensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,  y in train_dataloader:\n",
    "    print(\"X- minibatched: \", x)\n",
    "    print(\"y- minibatched: \", y)\n",
    "    break"
   ]
  },
  {
   "source": [
    "## Sanity test for out worker"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.curdir\n",
    "# minimum budget that BOHB uses\n",
    "min_budget = 1\n",
    "# largest budget BOHB will use\n",
    "max_budget = 9\n",
    "worker = PyTorchWorker(run_id='0', input_size=55, output_size=1, train_loader= train_dataloader, validation_loader= validation_dataloader, test_loader= test_dataloader)\n",
    "cs = worker.get_configspace()\n",
    "config = cs.sample_configuration().get_dictionary()\n",
    "print(\"Config: \", config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = worker.compute(config=config, budget=min_budget, working_directory=working_dir)\n",
    "print(res)"
   ]
  },
  {
   "source": [
    "## BOHB parameters and variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = os.path.join(working_dir, 'bohb_LC_result.pkl')\n",
    "nic_name = 'lo0'\n",
    "port = 0\n",
    "run_id = 'bohb_run_1'\n",
    "n_bohb_iterations = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    try:\n",
    "        host = hpns.nic_name_to_host(nic_name)\n",
    "    except ValueError as e:\n",
    "        host = \"localhost\"\n",
    "        print(e)\n",
    "        print(\"ValueError getting host from nic_name {}, \"\n",
    "              \"setting to localhost.\".format(nic_name))    \n",
    "    \n",
    "    ns = hpns.NameServer(run_id=run_id, host=host, port=port,\n",
    "                         working_directory=working_dir)\n",
    "    ns_host, ns_port = ns.start()\n",
    "\n",
    "    # Start local worker\n",
    "    w = PyTorchWorker(run_id=run_id, host=host, nameserver=ns_host,\n",
    "                      nameserver_port=ns_port, timeout=120, input_size=55, output_size=1, train_loader= train_dataloader, validation_loader= validation_dataloader, test_loader= test_dataloader)\n",
    "    w.run(background=True)\n",
    "\n",
    "    # Run an optimizer\n",
    "    bohb = BOHB(configspace=worker.get_configspace(),\n",
    "                run_id=run_id,\n",
    "                host=host,\n",
    "                nameserver=ns_host,\n",
    "                nameserver_port=ns_port,\n",
    "                min_budget=min_budget, max_budget=max_budget)\n",
    "\n",
    "    result = bohb.run(n_iterations=n_bohb_iterations)\n",
    "    print(\"Write result to file {}\".format(result_file))\n",
    "    with open(result_file, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "finally:\n",
    "    bohb.shutdown(shutdown_workers=True)\n",
    "    ns.shutdown()"
   ]
  },
  {
   "source": [
    "## Get best run"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_id = result.get_incumbent_id()  # get config_id of incumbent (lowest loss)\n",
    "inc_run = result.get_runs_by_id(inc_id)[-1]  # get run with this config_id on highest budget\n",
    "best_error, best_model = inc_run.loss, inc_run.info['model']\n",
    "print(\"The best model (config_id {}) has the lowest final error with {:.4f}.\"\n",
    "      .format(inc_run.config_id, best_error))\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = result.get_all_runs()\n",
    "id2conf = result.get_id2config_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpvis.finished_runs_over_time(all_runs, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpvis.correlation_across_budgets(result, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpvis.losses_over_time(all_runs, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpvis.performance_histogram_model_vs_random(all_runs, id2conf, show=True)"
   ]
  }
 ]
}